library(keras)
library(glmnet)
# downloading data and getting the train/test division
mnist <- dataset_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
# reshape
x_train <- array_reshape(x_train, c(nrow(x_train), 784))
x_test <- array_reshape(x_test, c(nrow(x_test), 784))
# rescale
x_train <- x_train / 255
x_test <- x_test / 255
# transform y to categorical
y_train_logit <- as.factor(y_train)
y_test_logit <- as.factor(y_test)
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
library(keras)
library(glmnet)
# Exercise 1 - logit
library(doParallel)
registerDoSEQ() # turning off parallel computation
# Exercise 1 - logit
# we test only on a subset, otherwise it is quite slow
logit <- cv.glmnet(x_train[1:1000, ], y_train_logit[1:1000], family = "multinomial")
pred_logit <- predict(logit, x_test[1:1000, ], type = "class")
mean(pred_logit == y_test_logit[1:1000])
cv.glmnet
logit
pred_logit == y_test_logit[1:1000]
# Neural networks
model <- keras_model_sequential()
model %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
summary(model)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
summary(model)
history <- model %>% fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
plot(history)
model %>% predict_classes(x_test) %>% head()
model %>% evaluate(x_test, y_test)
# logit in keras
model1 <- keras_model_sequential()
model1 %>%
layer_dense(units = 10, activation = 'sigmoid', input_shape = c(784)) %>%
summary(model1)
model1 %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
# Exercise 4
#
history1 <- model1 %>% fit(
x_train, y_train,
epochs = 30, batch_size = 128,
validation_split = 0.2
)
plot(history1)
model1 %>% predict_classes(x_test) %>% head()
model1 %>% evaluate(x_test, y_test)
